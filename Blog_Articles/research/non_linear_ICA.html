<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <title>Analysis and Math</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport" />
  <meta content="Free Website Template" name="keywords" />
  <meta content="Free Website Template" name="description" />

  <!-- Favicon -->
  <link href="img/favicon.ico" rel="icon" />

  <!-- Google Font -->
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap"
    rel="stylesheet" />

  <!-- CSS Libraries -->
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" />
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.10.0/css/all.min.css" rel="stylesheet" />
  <link href="lib/animate/animate.min.css" rel="stylesheet" />
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet" />
  <link href="lib/lightbox/css/lightbox.min.css" rel="stylesheet" />

  <!-- Template Stylesheet -->
  <link href="/css/style.css" rel="stylesheet" />
</head>

<body>
  <!-- Nav Bar Start -->
  <nav class="navbar navbar-expand-lg navbar-light position-fixed">
    <div class="container  justify-content-between">
        <a class="nav-item nav-link navbar-brand" href="/index.html#home">KOFFI IDONGESIT</a>
        <button class="navbar-toggler bg-white" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse flex-grow-0" id="navbarSupportedContent">
            <ul class="navbar-nav me-auto">
                <a class="nav-item nav-link" href="/index.html#home">Home</a>
                <a class="nav-item nav-link" href="/index.html#about" >About</a>
                <a href="/index.html#experience" class="nav-item nav-link">WHY ME</a>
                <a href="/index.html#blog" class="nav-item nav-link">Articles</a>
                <a href="/index.html#testimonial" class="nav-item nav-link">Reviews</a>
            </ul>
        </div>
    </div>
</nav>
  <!-- Nav Bar End -->

  <!-- Blog Start -->
  <div class="blog sub-blog" id="blog">
    <div class="container">
      <div class="section-header text-center wow zoomIn" data-wow-delay="0.1s">
        <!-- <p class="para">From Blog</p> -->
        <!-- <br /> -->
        <!-- <a class="btn" href="/sub_Blog/research.html"><i class="fa fa-angle-left"></i>Back</a> -->
      </div>
      <div class="p-3 write-ups wow zoomIn" data-wow-delay="0.1s">
           <h4 class="text-center">
            Nonlinear ICA Through Low-complexity Autoencoders
            </h4>
            <h5 class="text-center">Abstract</h5>
            <p>
                With the architectural nature of variational autoencoders, one is able to effectively train deep models that are latent-variable. This is done in such a way that the marginal supply error of the model as against the considered variables, is well suited to the raw information. More often than not, the interest is in taking an additional step with hopes to approximate the genuine juncture distribution over latent as well as observed variables—including the real anterior and posterior distributions in the midst of latent-type variables. Generally, this is known to be impossible—and much of that drawback has to do with the model’s non-identifiability. This issue is addressed through demonstration that when it comes to a large family of deep and latent-variable models, it is actually possible to identify the true joint distributions more than the noticed and latent variables. Because this is possible up to quite simple transformations, it is also possible to realize a powerful and principled type of un-entanglement. The outcomes we realized require factorized preceding distribution over the latent variables which are additionally conditioned on observed variables—including class labels or relatively any other kind of observation. In a nonlinear ICA, we build on the existing developments, from where the case is extended with noisy, discrete or incomplete observations—all of which are incorporated into a framework of maximum likelihood. Trivially, the result also comprises flow-based generative designs that are identifiable as special cases. We learn autoencoder using the Flat Minimum Search (also called the FMS) technique, which is a regularizer algorithm designed for locating and identifying systems with low complexity and describality by tidbits of information. As a by-product, this is an encouragement of non-linear, non-dependent element analysis (or ICA) and the input data’s sparse codes. In weight space, flat minima are regions where (a) it is possible to disrupt the weights without altering the output of the network and (b) there are small, tolerable inaccuracies. As such, the weights may be offered without optimal precision as some shreds of the data need to be descriptive of the aligning low-complexity or simple network. Generally, low network complexity is more related to high performances in generalization. In order to simplify the flat minima-finding algorithm, we refrain from considering the maximally connected environments to focus on the “boxes” within those environments. This happens for every weight vector that, leading to a negligible volume of error. In order to simplify the process, every box edge is considered parallel to a (one) weight axis.
            </p>
            <h5 class="text-center">
                Introduction
            </h5>
            <p>
                The physical structure of variational autoencoders—also called VAEs (Rezende et al., 2014; Kingma & Welling, 2013)—and its extensions (such as Kingma et al. (2016); Maaløe et al. (2019); Tucker et al. (2018); Burda et al. (2015) present scalable sets of methods for training deep latent variable designs as well as aligning inference models. Through the use of VAEs, it is a possibility to principally train flexible data models in a way which, post-optimization, the complicit marginal supply over the considered variables is an approximation of their real yet unknown distribution. Also, VAEs serve as the medium via which one can also effectively subject quasi-data to synthetization, that is, from the model. Be as it may, we usually are interested in taking an additional step to train the real joint distribution atop the latent and observed variables. 
            </p>
            <p>
                Generally, this is quite a difficult task—because, definitively, it is only observed variables that are ever observed, not the latent variables. Due to this, we will not be able to estimate their conjoined distribution accurately. Should we find other means to complete this task and train the real joint distribution, it would be an implication that we have also been able to learn the way to estimate the true anterior and posterior distributions against latent variables. Coming across these distributions is interesting for many reasons, chief of which are learning about the latent framework behind data and inferring the latent variables that form the data’s point of origin. 
            </p>

        



      </div>
      <div class="align-content-center mt-2 text-center wow zoomIn" data-wow-delay="0.1s">
        <a class="btn" href="/sub_Blog/research.html"><i class="fa fa-angle-left"></i>Back</a>
      </div>
    </div>
  </div>
  <!-- Blog End -->

  <!-- Footer Start -->
  <div class="footer mt-0 wow fadeIn" data-wow-delay="0.3s">
    <div class="container-fluid">
      <div class="container">
        <div class="footer-info">
          <h2>Idongesit Koffi</h2>
          <div class="footer-menu">
            <p>+234-706-455-1848</p>
            <p>koffijnr@gmail.com</p>
          </div>
        </div>
      </div>
      <div class="container copyright">
        <p>
          &copy; <a href="#">Your Site Name</a>, All Right Reserved | Designed
          By <a href="https://ezekielelom.com">Ellovick</a>
        </p>
        <a href="#" class="btn back-to-top"><i class="fa fa-chevron-up"></i></a>
      </div>
    </div>
  </div>
  <!-- Footer End -->

  <!-- Back to top button -->
  <a href="#" class="btn back-to-top"><i class="fa fa-chevron-up"></i></a>

  <!-- Pre Loader -->
  <!-- <div id="loader" class="show">
         <div class="loader"></div>
     </div> -->

  <!-- JavaScript Libraries -->
  <script src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>

  <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous"> -->

  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js"
    integrity="sha384-7+zCNj/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js"
    integrity="sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13"
    crossorigin="anonymous"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/waypoints/waypoints.min.js"></script>
  <script src="lib/typed/typed.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>
  <script src="lib/isotope/isotope.pkgd.min.js"></script>
  <script src="lib/lightbox/js/lightbox.min.js"></script>

  <!-- Contact Javascript File -->
  <script src="mail/jqBootstrapValidation.min.js"></script>
  <script src="mail/contact.js"></script>

  <!-- Template Javascript -->
  <script src="js/main.js"></script>
</body>

</html>